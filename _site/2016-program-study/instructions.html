
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<link rel="stylesheet" type="text/css" href="main.css" /> 

<title>Atoms of Confusion User Study</title>

</head>
<body>

<table id="main">

<tr><td>

<!-- ------------------------------------- -->

<table border="0" width="100%">
<tr>
<h2>Atoms Impact Experiment Materials</h2>

<h3>Goals</h3>

<p>Testing atoms isolated in minimal examples, like in the atoms 
existence experiment, is crucial for gaining a rigorous understanding 
of the relative confusion and removability of an individual atom. To 
broaden our understanding of how multiple atoms affect larger bodies 
of code, we tested their impact on a broader sample from the source of 
the code snippets. The experiment used winning programs from the IOCCC 
to test subjects' ability to hand evaluate each full program. For each 
code sample, half of our subjects performed the hand evaluation task 
on code in its near-original form, and the other half evaluated the same 
code after all of its known atoms were removed. Our hypothesis was that 
programmers would make fewer evaluation errors on code which had its 
atoms of confusion removed.</p>

<p>With the data from this experiment we will explore the following 
questions:</p>

<ul>
<li>
Are clarified programs evaluated more accurately than obfuscated programs?	
</li>

<li>
What other ways can we measure subject performance?	
</li>

<li>
Which code was still confusing in clarified questions?	
</li>
</ul>

<p>We recruited 43 programmers with at least 6 months experience with C or 
C++. We presented them (1) small programs (between 14-84 lines) containing 
several atoms of confusion, and (2) a version of the same programs 
transformed to remove the atoms of confusion. The subjects were asked to 
hand evaluate the output of both versions of the programs. We would like 
to verify that <i>multiple atoms of confusion cause more errors than other 
code in hand-evaluated outputs</i>.
</p>

<hr/>
<h3>Pre-study</h3>
<p>
Before doing the experiment, all subjects needed to sign a 
<a href="consent.pdf">consent form</a>. This form explains the purpose
of this experiment, and informs the subject that the participation is
voluntary.
</p>

</ul>

<hr/>
</ul><h3>Core materials</h3>

<h4>Instructions</h4>

We designed instructions for <a href="in-person.html">in-person</a> 
study, and <a href="remote.html">remote</a> study, as some of our
subjects were remote. 

<h4>Questions and sample answers</h4>

<p>In total, we designed four programs, each with its confusing (with 
atoms) and non-confusing version (with atoms removed). The full list
of programs can be found <a href="questions.html">here</a>. They are 
named as question A/B/C/D/E/F/G/H, respectively. For example, question 
A and B are the confusing and non-confusing version of the same program.
For each subject, we chose a random subset of four out of the eight questions, 
and made sure that they do not see both the confusing and non-confusing
version of the same program.</p>

<p>After each experiment with a subject, we scanned the hand written 
results, normalized and transcribed the results. Here is a 
<a href="sample.html">sample answer</a> from a subject after we obtained 
consent. The answer includes both the hand written and the transcribed 
versions.</p>

Full data set (normalized and transcribed) will be available 
soon.

<hr/>
</ul><h3>Post-study</h3>

Subjects completed a <a href="survey.pdf">demographic survey</a>
after finishing all the questions. 

</table>

</body>
</html>
